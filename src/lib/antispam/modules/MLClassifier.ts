/**
 * MLClassifier - Machine Learning-based spam classification
 * Uses feature extraction and pattern learning to detect evolving threats
 */

import { FormSubmission, Threat, ThreatType, MLFeatures, ValidationResult } from '../types';

interface TrainingData {
  features: MLFeatures;
  label: 'spam' | 'ham';
  confidence: number;
  timestamp: Date;
}

interface Model {
  version: string;
  weights: Map<string, number>;
  bias: number;
  featureMeans: Map<string, number>;
  featureStdDevs: Map<string, number>;
  threshold: number;
  accuracy: number;
  trainingSamples: number;
}

export class MLClassifier {
  private model: Model;
  private trainingData: TrainingData[] = [];
  private readonly maxTrainingData = 10000;
  private readonly minTrainingSamples = 100;
  private aiPatterns = {
    gptStyle: [
      /\bAs an AI\b/i,
      /\bI understand your concern\b/i,
      /\bIt's important to note\b/i,
      /\bHowever, it's worth mentioning\b/i,
      /\bIn conclusion\b/i,
      /\bTo summarize\b/i,
      /\bFirstly.*Secondly.*Finally\b/is
    ],
    repetitiveStructure: /(\b\w+\b)(?=.*\b\1\b.*\b\1\b.*\b\1\b)/gi,
    unnaturalPhrasing: [
      /\bkindly\s+\w+\s+(?:me|us)\b/i,
      /\bdo the needful\b/i,
      /\brevert back\b/i,
      /\bintimate me\b/i
    ]
  };

  constructor() {
    this.model = this.initializeModel();
    this.loadStoredModel();
  }

  private initializeModel(): Model {
    return {
      version: '1.0.0',
      weights: new Map(),
      bias: 0,
      featureMeans: new Map(),
      featureStdDevs: new Map(),
      threshold: 0.5,
      accuracy: 0,
      trainingSamples: 0
    };
  }

  async classify(submission: FormSubmission): Promise<{ threats: Threat[]; confidence: number }> {
    const threats: Threat[] = [];
    
    // Extract features
    const features = this.extractFeatures(submission);
    
    // Check for AI-generated content
    const aiDetection = this.detectAIGenerated(submission);
    if (aiDetection.isAI) {
      threats.push({
        type: ThreatType.AI_GENERATED,
        pattern: 'AI-generated content',
        confidence: aiDetection.confidence,
        description: 'Content appears to be generated by AI',
        evidence: aiDetection.evidence,
        severity: 'medium'
      });
    }
    
    // Normalize features
    const normalizedFeatures = this.normalizeFeatures(features);
    
    // Calculate spam probability
    const spamProbability = this.calculateSpamProbability(normalizedFeatures);
    
    // Detect anomalies
    const anomalyScore = this.detectAnomalies(features);
    
    // Combine scores
    const finalConfidence = Math.max(spamProbability, anomalyScore);
    
    if (finalConfidence > this.model.threshold) {
      threats.push({
        type: ThreatType.SUSPICIOUS_KEYWORDS,
        pattern: 'ML classification',
        confidence: finalConfidence,
        description: 'Machine learning model detected suspicious patterns',
        evidence: this.getTopFeatures(features),
        severity: finalConfidence > 0.8 ? 'high' : 'medium'
      });
    }
    
    return { threats, confidence: finalConfidence };
  }

  private extractFeatures(submission: FormSubmission): MLFeatures {
    const allText = Object.values(submission.fields)
      .filter(v => typeof v === 'string')
      .join(' ');
    
    const words = allText.split(/\s+/);
    const uniqueWords = new Set(words);
    
    // Extract URLs
    const urlMatches = allText.match(/https?:\/\/[^\s]+/gi) || [];
    const domains = new Set(urlMatches.map(url => {
      try {
        return new URL(url).hostname;
      } catch {
        return null;
      }
    }).filter(Boolean));
    
    // Count suspicious URLs
    const suspiciousUrls = urlMatches.filter(url => 
      /\.(tk|ml|ga|cf|click|download|review|top|loan|work|men|date|party|racing|win|stream|gdn)\b/i.test(url) ||
      /bit\.ly|tinyurl|goo\.gl/i.test(url)
    ).length;
    
    // Count shortener URLs
    const shortenerUrls = urlMatches.filter(url =>
      /bit\.ly|tinyurl|goo\.gl|ow\.ly|t\.co|short\.link|rebrand\.ly/i.test(url)
    ).length;
    
    // Calculate text statistics
    const textLength = allText.length;
    const capitalLetters = (allText.match(/[A-Z]/g) || []).length;
    const punctuation = (allText.match(/[.,!?;:'"]/g) || []).length;
    const digits = (allText.match(/\d/g) || []).length;
    const specialChars = (allText.match(/[^a-zA-Z0-9\s]/g) || []).length;
    
    // Calculate sentiment and urgency scores
    const { sentimentScore, urgencyScore } = this.analyzeTextSentiment(allText);
    
    // Calculate complexity score (vocabulary diversity)
    const complexityScore = uniqueWords.size / Math.max(words.length, 1);
    
    // Calculate Shannon entropy
    const shannonEntropy = this.calculateShannonEntropy(allText);
    
    // Behavioral features
    const metadata = submission.metadata;
    
    return {
      textLength,
      wordCount: words.length,
      uniqueWords: uniqueWords.size,
      avgWordLength: words.reduce((sum, w) => sum + w.length, 0) / Math.max(words.length, 1),
      capitalRatio: capitalLetters / Math.max(textLength, 1),
      punctuationRatio: punctuation / Math.max(textLength, 1),
      digitRatio: digits / Math.max(textLength, 1),
      specialCharRatio: specialChars / Math.max(textLength, 1),
      urlCount: urlMatches.length,
      uniqueDomains: domains.size,
      suspiciousUrls,
      shortenerUrls,
      shannonEntropy,
      sentimentScore,
      urgencyScore,
      complexityScore,
      submissionTime: metadata.submissionTime || 0,
      fieldInteractions: metadata.fieldFocusOrder?.length || 0,
      correctionCount: metadata.keystrokes || 0,
      browserAge: 0, // Would need to track this
      cookiesEnabled: true, // Would need to detect
      jsEnabled: true, // Would need to detect
      pluginCount: metadata.plugins?.length || 0
    };
  }

  private detectAIGenerated(submission: FormSubmission): {
    isAI: boolean;
    confidence: number;
    evidence: string[];
  } {
    const allText = Object.values(submission.fields)
      .filter(v => typeof v === 'string')
      .join(' ');
    
    const evidence: string[] = [];
    let score = 0;
    
    // Check for GPT-style phrases
    for (const pattern of this.aiPatterns.gptStyle) {
      if (pattern.test(allText)) {
        score += 0.2;
        const match = allText.match(pattern);
        if (match) evidence.push(match[0]);
      }
    }
    
    // Check for repetitive structure (AI often repeats patterns)
    const repetitions = allText.match(this.aiPatterns.repetitiveStructure);
    if (repetitions && repetitions.length > 5) {
      score += 0.3;
      evidence.push('Repetitive word patterns detected');
    }
    
    // Check for unnatural phrasing
    for (const pattern of this.aiPatterns.unnaturalPhrasing) {
      if (pattern.test(allText)) {
        score += 0.15;
        const match = allText.match(pattern);
        if (match) evidence.push(match[0]);
      }
    }
    
    // Check for perfect grammar in spam context
    const sentences = allText.split(/[.!?]+/);
    const longSentences = sentences.filter(s => s.split(/\s+/).length > 20);
    if (longSentences.length > 2 && !allText.match(/[.!?]{2,}/)) {
      score += 0.2;
      evidence.push('Unnaturally perfect sentence structure');
    }
    
    // Check for lack of typos in long text
    if (allText.length > 500) {
      const commonTypos = /\b(teh|recieve|occured|untill|wich|wierd)\b/gi;
      if (!commonTypos.test(allText)) {
        score += 0.1;
        evidence.push('No typos in long text');
      }
    }
    
    return {
      isAI: score > 0.5,
      confidence: Math.min(score, 0.95),
      evidence: evidence.slice(0, 3)
    };
  }

  private analyzeTextSentiment(text: string): {
    sentimentScore: number;
    urgencyScore: number;
  } {
    // Negative words (indicating potential scam/spam)
    const negativeWords = /\b(urgent|expire|suspend|delete|terminate|limited|deadline|act now|hurry|last chance)\b/gi;
    const positiveWords = /\b(free|winner|congratulations|prize|reward|bonus|guaranteed|amazing|incredible)\b/gi;
    
    const negativeMatches = (text.match(negativeWords) || []).length;
    const positiveMatches = (text.match(positiveWords) || []).length;
    
    const words = text.split(/\s+/).length;
    
    // High sentiment (either very positive or very negative) is suspicious
    const sentimentScore = (negativeMatches + positiveMatches) / Math.max(words, 1);
    
    // Urgency score based on time-pressure words
    const urgencyWords = /\b(now|today|immediate|instant|quick|fast|hurry|expire|deadline|limited time|act now|don't wait)\b/gi;
    const urgencyMatches = (text.match(urgencyWords) || []).length;
    const urgencyScore = urgencyMatches / Math.max(words, 1);
    
    return { sentimentScore, urgencyScore };
  }

  private calculateShannonEntropy(text: string): number {
    const freq: Map<string, number> = new Map();
    
    for (const char of text.toLowerCase()) {
      freq.set(char, (freq.get(char) || 0) + 1);
    }
    
    let entropy = 0;
    const len = text.length;
    
    for (const count of freq.values()) {
      const p = count / len;
      if (p > 0) {
        entropy -= p * Math.log2(p);
      }
    }
    
    return entropy;
  }

  private normalizeFeatures(features: MLFeatures): Map<string, number> {
    const normalized = new Map<string, number>();
    
    for (const [key, value] of Object.entries(features)) {
      if (typeof value === 'number') {
        const mean = this.model.featureMeans.get(key) || 0;
        const stdDev = this.model.featureStdDevs.get(key) || 1;
        
        // Z-score normalization
        normalized.set(key, (value - mean) / stdDev);
      } else if (typeof value === 'boolean') {
        normalized.set(key, value ? 1 : 0);
      }
    }
    
    return normalized;
  }

  private calculateSpamProbability(features: Map<string, number>): number {
    // Simple logistic regression
    let score = this.model.bias;
    
    for (const [feature, value] of features) {
      const weight = this.model.weights.get(feature) || 0;
      score += weight * value;
    }
    
    // Sigmoid activation
    return 1 / (1 + Math.exp(-score));
  }

  private detectAnomalies(features: MLFeatures): number {
    let anomalyScore = 0;
    let anomalyCount = 0;
    
    // Check for extreme values
    if (features.urlCount > 10) {
      anomalyScore += 0.3;
      anomalyCount++;
    }
    
    if (features.capitalRatio > 0.5) {
      anomalyScore += 0.2;
      anomalyCount++;
    }
    
    if (features.specialCharRatio > 0.3) {
      anomalyScore += 0.2;
      anomalyCount++;
    }
    
    if (features.urgencyScore > 0.1) {
      anomalyScore += 0.3;
      anomalyCount++;
    }
    
    if (features.shannonEntropy > 5 || features.shannonEntropy < 2) {
      anomalyScore += 0.2;
      anomalyCount++;
    }
    
    if (features.submissionTime < 2000) {
      anomalyScore += 0.4;
      anomalyCount++;
    }
    
    // Normalize by number of anomalies
    return anomalyCount > 0 ? Math.min(anomalyScore / anomalyCount * 2, 0.95) : 0;
  }

  private getTopFeatures(features: MLFeatures): string[] {
    const evidence: string[] = [];
    
    if (features.urlCount > 3) {
      evidence.push(`${features.urlCount} URLs detected`);
    }
    
    if (features.urgencyScore > 0.05) {
      evidence.push(`High urgency score: ${(features.urgencyScore * 100).toFixed(1)}%`);
    }
    
    if (features.capitalRatio > 0.3) {
      evidence.push(`Excessive capitals: ${(features.capitalRatio * 100).toFixed(1)}%`);
    }
    
    if (features.shannonEntropy > 4.5) {
      evidence.push(`High text entropy: ${features.shannonEntropy.toFixed(2)}`);
    }
    
    return evidence.slice(0, 3);
  }

  async learn(submission: FormSubmission, result: ValidationResult) {
    const features = this.extractFeatures(submission);
    const label = result.threatLevel === 'none' ? 'ham' : 'spam';
    
    // Add to training data
    this.trainingData.push({
      features,
      label,
      confidence: result.confidence,
      timestamp: new Date()
    });
    
    // Limit training data size
    if (this.trainingData.length > this.maxTrainingData) {
      this.trainingData.shift();
    }
    
    // Retrain if we have enough samples
    if (this.trainingData.length >= this.minTrainingSamples &&
        this.trainingData.length % 100 === 0) {
      await this.retrain();
    }
  }

  private async retrain() {
    // Update feature statistics
    this.updateFeatureStatistics();
    
    // Simple online learning - update weights based on recent mistakes
    // In production, this would use a more sophisticated algorithm
    
    const learningRate = 0.01;
    const recentData = this.trainingData.slice(-100);
    
    for (const data of recentData) {
      const normalizedFeatures = this.normalizeFeatures(data.features);
      const prediction = this.calculateSpamProbability(normalizedFeatures);
      const target = data.label === 'spam' ? 1 : 0;
      const error = target - prediction;
      
      // Update weights using gradient descent
      for (const [feature, value] of normalizedFeatures) {
        const currentWeight = this.model.weights.get(feature) || 0;
        const newWeight = currentWeight + learningRate * error * value;
        this.model.weights.set(feature, newWeight);
      }
      
      // Update bias
      this.model.bias += learningRate * error;
    }
    
    this.model.trainingSamples = this.trainingData.length;
    this.model.version = this.incrementVersion(this.model.version);
    
    // Save updated model
    await this.saveModel();
  }

  private updateFeatureStatistics() {
    const allFeatures: Map<string, number[]> = new Map();
    
    // Collect all feature values
    for (const data of this.trainingData) {
      for (const [key, value] of Object.entries(data.features)) {
        if (typeof value === 'number') {
          if (!allFeatures.has(key)) {
            allFeatures.set(key, []);
          }
          allFeatures.get(key)!.push(value);
        }
      }
    }
    
    // Calculate means and standard deviations
    for (const [feature, values] of allFeatures) {
      const mean = values.reduce((sum, v) => sum + v, 0) / values.length;
      const variance = values.reduce((sum, v) => sum + Math.pow(v - mean, 2), 0) / values.length;
      const stdDev = Math.sqrt(variance);
      
      this.model.featureMeans.set(feature, mean);
      this.model.featureStdDevs.set(feature, stdDev || 1);
    }
  }

  async feedback(submissionId: string, wasSpam: boolean) {
    // Update model based on manual review feedback
    // This would need to store submission data for learning
    console.log(`Feedback received: ${submissionId} was ${wasSpam ? 'spam' : 'not spam'}`);
  }

  private incrementVersion(version: string): string {
    const parts = version.split('.');
    parts[2] = String(parseInt(parts[2]) + 1);
    return parts.join('.');
  }

  private async saveModel() {
    // In production, save to database or file system
    if (typeof window !== 'undefined' && window.localStorage) {
      const modelData = {
        version: this.model.version,
        weights: Array.from(this.model.weights.entries()),
        bias: this.model.bias,
        featureMeans: Array.from(this.model.featureMeans.entries()),
        featureStdDevs: Array.from(this.model.featureStdDevs.entries()),
        threshold: this.model.threshold,
        trainingSamples: this.model.trainingSamples
      };
      
      localStorage.setItem('spamguard_ml_model', JSON.stringify(modelData));
    }
  }

  private loadStoredModel() {
    // In production, load from database or file system
    if (typeof window !== 'undefined' && window.localStorage) {
      const stored = localStorage.getItem('spamguard_ml_model');
      if (stored) {
        try {
          const modelData = JSON.parse(stored);
          this.model.version = modelData.version;
          this.model.weights = new Map(modelData.weights);
          this.model.bias = modelData.bias;
          this.model.featureMeans = new Map(modelData.featureMeans);
          this.model.featureStdDevs = new Map(modelData.featureStdDevs);
          this.model.threshold = modelData.threshold;
          this.model.trainingSamples = modelData.trainingSamples;
        } catch (error) {
          console.error('Failed to load stored model:', error);
        }
      }
    }
  }

  getVersion(): string {
    return this.model.version;
  }

  getModelStats() {
    return {
      version: this.model.version,
      trainingSamples: this.model.trainingSamples,
      accuracy: this.model.accuracy,
      features: this.model.weights.size,
      threshold: this.model.threshold
    };
  }
}